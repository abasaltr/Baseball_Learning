{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Clean CSV Data and Add to SQL Database</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import Dependencies</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import sqlite3\n",
    "import csv\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from config import pgPassword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create paths to CSV files</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathTeams = os.path.join(\"..\", \"..\", \"data\", \"csv\", \"Teams.csv\")\n",
    "pathBatting = os.path.join(\"..\", \"..\", \"data\", \"csv\", \"Batting.csv\")\n",
    "pathPitching = os.path.join(\"..\", \"..\", \"data\", \"csv\", \"Pitching.csv\")\n",
    "pathPlayers = os.path.join(\"..\", \"..\", \"data\", \"csv\", \"People.csv\")\n",
    "pathFranchises = os.path.join(\"..\", \"..\", \"data\", \"csv\", \"TeamsFranchises.csv\")\n",
    "pathSalaries = os.path.join(\"..\", \"..\", \"data\", \"csv\", \"Salaries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Load CSV files into DataFrame and clean</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\..\\\\data\\\\csv\\\\TeamsFranchises.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-70205471763e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Read csv into a DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfranchisesDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathFranchises\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Trim off unwanted columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfranchisesCols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"franchID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"franchName\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfranchisesDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfranchisesDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfranchisesCols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 936\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1168\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1169\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1998\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\..\\\\data\\\\csv\\\\TeamsFranchises.csv'"
     ]
    }
   ],
   "source": [
    "# Read csv into a DataFrame\n",
    "franchisesDF = pd.read_csv(pathFranchises)\n",
    "# Trim off unwanted columns\n",
    "franchisesCols = [\"franchID\", \"franchName\"]\n",
    "franchisesDF = franchisesDF[franchisesCols]\n",
    "franchisesDF = franchisesDF.rename(columns={'franchID': 'franchiseID'})\n",
    "franchisesDF = franchisesDF.rename(columns={'franchName': 'FranchiseName'})\n",
    "franchisesDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv into a DataFrame\n",
    "teamsDF = pd.read_csv(pathTeams)\n",
    "# Trim off unwanted columns\n",
    "teamsCols = [\"franchID\", \"teamID\", \"name\", \"yearID\", \"G\", \"W\", \"R\", \"H\", \"HR\", \"BB\", \"SO\", \"SB\", \"RA\", \"ERA\", \"HA\", \"HRA\", \"BBA\", \"SOA\"]\n",
    "teamsDF = teamsDF[teamsCols]\n",
    "teamsDF = teamsDF.rename(columns={'franchID': 'franchiseID'})\n",
    "teamsDF['statID'] = teamsDF.index\n",
    "teamsDF['teamIDy'] = teamsDF.index\n",
    "for i in range(len(teamsDF)): \n",
    "     teamsDF.loc[i, 'statID'] = ((i+1)**2)+999,\n",
    "     teamsDF.loc[i, 'teamIDy'] = teamsDF.loc[i,'teamID'] + \"-\" + str(teamsDF.loc[i,'yearID'])\n",
    "\n",
    "teamsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teamsDF[pd.isnull(teamsDF).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teamsDF2 = pd.DataFrame()\n",
    "teamsDF2['teamID'] = teamsDF['teamIDy']\n",
    "teamsDF2['TeamName'] = teamsDF['name']\n",
    "teamsDF2 = teamsDF2.drop_duplicates()\n",
    "teamsDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_statsDF = teamsDF.copy()\n",
    "team_statsDF = team_statsDF[team_statsDF.columns.drop('name')]\n",
    "team_statsDF = team_statsDF[team_statsDF.columns.drop('teamID')]\n",
    "team_statsDF = team_statsDF.rename(columns={'teamIDy': 'teamID'})\n",
    "team_statsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_statsDF2 = team_statsDF.fillna(0)\n",
    "team_statsDF2[pd.isnull(team_statsDF2).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_statsDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv into a DataFrame\n",
    "playersDF = pd.read_csv(pathPlayers)\n",
    "# Trim off unwanted columns\n",
    "playersCols = [\"playerID\", \"birthYear\", \"nameFirst\", \"nameLast\", \"debut\", \"finalGame\"]\n",
    "playersDF = playersDF[playersCols]\n",
    "playersDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playersDF[pd.isnull(playersDF).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playersDF2 = playersDF.copy()\n",
    "playersDF2['birthYear'] = playersDF2['birthYear'].fillna(0)\n",
    "playersDF2['debut'] = playersDF2['debut'].fillna('2021-01-01')\n",
    "playersDF2['finalGame'] = playersDF2['finalGame'].fillna('2021-01-01')\n",
    "playersDF2['nameFirst'] = playersDF2['nameFirst'].fillna(\"NA\")\n",
    "playersDF2[pd.isnull(playersDF2).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv into a DataFrame\n",
    "salariesDF = pd.read_csv(pathSalaries)\n",
    "# Trim off unwanted columns\n",
    "salariesCols = [\"yearID\", \"teamID\", \"playerID\", \"salary\"]\n",
    "salariesDF = salariesDF[salariesCols]\n",
    "salariesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_df = salariesDF.copy()\n",
    "FP_df['fpID'] = FP_df.index\n",
    "for i in range(len(FP_df)):\n",
    "     FP_df.loc[i, 'fpID'] = ((i+1)**2)+999\n",
    "FP_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_df2 = pd.merge(FP_df, teamsDF, on=[\"teamID\",\"yearID\"])\n",
    "FP_df3 = pd.DataFrame()\n",
    "FP_df3['fpID'] = FP_df2['fpID']\n",
    "FP_df3['franchiseID'] = FP_df2['franchiseID']\n",
    "FP_df3['teamID'] = FP_df2['teamID'] \n",
    "FP_df3['yearID'] = FP_df2['yearID']\n",
    "FP_df3['playerID'] = FP_df2['playerID']\n",
    "FP_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_df3['teamIDy'] = FP_df3.index\n",
    "for i in range(len(FP_df3)): \n",
    "     FP_df3.loc[i, 'teamIDy'] = FP_df3.loc[i,'teamID'] + \"-\" + str(FP_df3.loc[i,'yearID'])\n",
    "FP_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_df4 = FP_df3.copy()\n",
    "FP_df4 = FP_df4[FP_df4.columns.drop('teamID')]\n",
    "FP_df4 = FP_df4[FP_df4.columns.drop('yearID')]\n",
    "FP_df4 = FP_df4.rename(columns={'teamIDy': 'teamID'})\n",
    "FP_df4 = FP_df4.drop_duplicates()\n",
    "FP_df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salariesDF2 = FP_df.copy()\n",
    "salariesDF2 = salariesDF2[salariesDF2.columns.drop('playerID')]\n",
    "salariesDF2 = salariesDF2[salariesDF2.columns.drop('teamID')]\n",
    "salariesDF2['salaryID'] = salariesDF2.index\n",
    "salariesDF2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(salariesDF2)):\n",
    "     salariesDF2.loc[i, 'salaryID'] = ((i+1)**2)+111\n",
    "salariesDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_df2 = FP_df.copy()\n",
    "FP_df2 = FP_df2[FP_df2.columns.drop('yearID')]\n",
    "FP_df2 = FP_df2[FP_df2.columns.drop('salary')]\n",
    "FP_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv into a DataFrame\n",
    "battingDF = pd.read_csv(pathBatting)\n",
    "# Trim off unwanted columns\n",
    "battingCols = [\"playerID\", \"yearID\",\"teamID\", \"stint\", \"G\", \"R\", \"H\", \"HR\", \"BB\", \"IBB\", \"SO\", \"SB\"]\n",
    "battingDF = battingDF[battingCols]\n",
    "battingDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newBattingDF = pd.merge(battingDF, FP_df2, on=\"playerID\")\n",
    "newBattingDF = newBattingDF[newBattingDF.columns.drop('playerID')]\n",
    "newBattingDF = newBattingDF[newBattingDF.columns.drop('teamID_x')]\n",
    "newBattingDF = newBattingDF[newBattingDF.columns.drop('teamID_y')]\n",
    "newBattingDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newBattingDF[pd.isnull(newBattingDF).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newBattingDF2 = newBattingDF.copy()\n",
    "newBattingDF2['IBB'] = newBattingDF2['IBB'].fillna(0)\n",
    "newBattingDF2[pd.isnull(newBattingDF2).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv into a DataFrame\n",
    "pitchingDF = pd.read_csv(pathPitching)\n",
    "# Trim off unwanted columns\n",
    "pitchingCols = [\"playerID\", \"yearID\", \"teamID\",\"stint\", \"G\", \"H\", \"HR\", \"BB\", \"SO\", \"ERA\", \"R\"]\n",
    "pitchingDF = pitchingDF[pitchingCols]\n",
    "pitchingDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPitchingDF = pd.merge(pitchingDF, FP_df2, on=\"playerID\")\n",
    "newPitchingDF = newPitchingDF[newPitchingDF.columns.drop('playerID')]\n",
    "newPitchingDF = newPitchingDF[newPitchingDF.columns.drop('teamID_x')]\n",
    "newPitchingDF = newPitchingDF[newPitchingDF.columns.drop('teamID_y')]\n",
    "newPitchingDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPitchingDF[pd.isnull(newPitchingDF).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPitchingDF2 = newPitchingDF.copy()\n",
    "newPitchingDF2['ERA'] = newPitchingDF2['ERA'].fillna(0)\n",
    "newPitchingDF2[pd.isnull(newPitchingDF2).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>===========================================================</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Set up SQL DataBase</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running of the cells below- <b>\n",
    "    in pgAdmin: create a DataBase named 'baseballDB'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create a connection to SQL database</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_user = 'postgres'\n",
    "pg_password = pgPassword\n",
    "db_name = 'baseball_db'\n",
    "\n",
    "connection_string = f\"{pg_user}:{pg_password}@localhost:5432/{db_name}\"\n",
    "engine = create_engine(f'postgresql://{connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Add dataframes to SQL database</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "franchisesDF.to_sql(name = \"Franchises\", con = engine, if_exists='append', index=False)\n",
    "print(\"franchise loaded success...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teamsDF2.to_sql(name = \"Teams\", con = engine, if_exists='append', index=False)\n",
    "print(\"Teams loaded success...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_statsDF2.to_sql(name = \"Team-Stats\", con = engine, if_exists='append', index=False)\n",
    "print(\"Team-Stats loaded success...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playersDF2.to_sql(name = \"Players\", con = engine, if_exists='append', index=False)\n",
    "print(\"Players loaded success...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_df4.to_sql(name = \"FranchisePlayers\", con = engine, if_exists='append', index=False)\n",
    "print(\"FranchisePlayers loaded success...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newBattingDF2.to_sql(name = \"Batting\", con = engine, if_exists='append', index=False)\n",
    "print(\"Batting loaded success...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPitchingDF2.to_sql(name = \"Pitching\", con = engine, if_exists='append', index=False)\n",
    "print(\"Pitching loaded success...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salariesDF2.to_sql(name = \"Salaries\", con = engine, if_exists='append', index=False)\n",
    "print(\"Salaries loaded success...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
