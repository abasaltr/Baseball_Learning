{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TEAM Prediction Machine Learning Models - Batting</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import Dependencies</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "import sqlite3\n",
    "import csv\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from config import pgPassword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Create a connection to SQL database</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_user = 'postgres'\n",
    "pg_password = pgPassword\n",
    "db_name = 'baseball_db'\n",
    "\n",
    "connection_string = f\"{pg_user}:{pg_password}@localhost:5432/{db_name}\"\n",
    "engine = create_engine(f'postgresql://{connection_string}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Read in databases tables as DatFrames</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "teamsStatsDF = pd.read_sql_table(\"Team-Stats\", con = engine)\n",
    "battingDF = pd.read_sql_table(\"Batting\", con = engine)\n",
    "pitchingDF = pd.read_sql_table(\"Pitching\", con = engine)\n",
    "playersDF = pd.read_sql_table(\"Players\", con = engine)\n",
    "franchisesDF = pd.read_sql_table(\"Franchises\", con = engine)\n",
    "salariesDF = pd.read_sql_table(\"Salaries\", con = engine)\n",
    "teamsDF = pd.read_sql_table(\"Teams\", con = engine)\n",
    "fPlayersDF = pd.read_sql_table(\"FranchisePlayers\", con = engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>franchiseID</th>\n",
       "      <th>yearID</th>\n",
       "      <th>G</th>\n",
       "      <th>W</th>\n",
       "      <th>R</th>\n",
       "      <th>H</th>\n",
       "      <th>HR</th>\n",
       "      <th>BB</th>\n",
       "      <th>SO</th>\n",
       "      <th>SB</th>\n",
       "      <th>RA</th>\n",
       "      <th>ERA</th>\n",
       "      <th>HA</th>\n",
       "      <th>HRA</th>\n",
       "      <th>BBA</th>\n",
       "      <th>SOA</th>\n",
       "      <th>statID</th>\n",
       "      <th>teamID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>ATL</td>\n",
       "      <td>1980</td>\n",
       "      <td>161</td>\n",
       "      <td>81</td>\n",
       "      <td>630</td>\n",
       "      <td>1352</td>\n",
       "      <td>144</td>\n",
       "      <td>434.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>660</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1397</td>\n",
       "      <td>131</td>\n",
       "      <td>454</td>\n",
       "      <td>696</td>\n",
       "      <td>3197943</td>\n",
       "      <td>ATL-1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>BAL</td>\n",
       "      <td>1980</td>\n",
       "      <td>162</td>\n",
       "      <td>100</td>\n",
       "      <td>805</td>\n",
       "      <td>1523</td>\n",
       "      <td>156</td>\n",
       "      <td>587.0</td>\n",
       "      <td>766.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>640</td>\n",
       "      <td>3.64</td>\n",
       "      <td>1438</td>\n",
       "      <td>134</td>\n",
       "      <td>507</td>\n",
       "      <td>789</td>\n",
       "      <td>3201520</td>\n",
       "      <td>BAL-1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>BOS</td>\n",
       "      <td>1980</td>\n",
       "      <td>160</td>\n",
       "      <td>83</td>\n",
       "      <td>757</td>\n",
       "      <td>1588</td>\n",
       "      <td>162</td>\n",
       "      <td>475.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>767</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1557</td>\n",
       "      <td>129</td>\n",
       "      <td>481</td>\n",
       "      <td>696</td>\n",
       "      <td>3205099</td>\n",
       "      <td>BOS-1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>ANA</td>\n",
       "      <td>1980</td>\n",
       "      <td>160</td>\n",
       "      <td>65</td>\n",
       "      <td>698</td>\n",
       "      <td>1442</td>\n",
       "      <td>106</td>\n",
       "      <td>539.0</td>\n",
       "      <td>889.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>797</td>\n",
       "      <td>4.52</td>\n",
       "      <td>1548</td>\n",
       "      <td>141</td>\n",
       "      <td>529</td>\n",
       "      <td>725</td>\n",
       "      <td>3208680</td>\n",
       "      <td>CAL-1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>CHW</td>\n",
       "      <td>1980</td>\n",
       "      <td>162</td>\n",
       "      <td>70</td>\n",
       "      <td>587</td>\n",
       "      <td>1408</td>\n",
       "      <td>91</td>\n",
       "      <td>399.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>722</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1434</td>\n",
       "      <td>108</td>\n",
       "      <td>563</td>\n",
       "      <td>724</td>\n",
       "      <td>3212263</td>\n",
       "      <td>CHA-1980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     franchiseID  yearID    G    W    R     H   HR     BB     SO     SB   RA  \\\n",
       "1787         ATL    1980  161   81  630  1352  144  434.0  899.0   73.0  660   \n",
       "1788         BAL    1980  162  100  805  1523  156  587.0  766.0  111.0  640   \n",
       "1789         BOS    1980  160   83  757  1588  162  475.0  720.0   79.0  767   \n",
       "1790         ANA    1980  160   65  698  1442  106  539.0  889.0   91.0  797   \n",
       "1791         CHW    1980  162   70  587  1408   91  399.0  670.0   68.0  722   \n",
       "\n",
       "       ERA    HA  HRA  BBA  SOA   statID    teamID  \n",
       "1787  3.77  1397  131  454  696  3197943  ATL-1980  \n",
       "1788  3.64  1438  134  507  789  3201520  BAL-1980  \n",
       "1789  4.38  1557  129  481  696  3205099  BOS-1980  \n",
       "1790  4.52  1548  141  529  725  3208680  CAL-1980  \n",
       "1791  3.92  1434  108  563  724  3212263  CHA-1980  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teamsStatsDF.head()\n",
    "teamsStatsDF.shape\n",
    "teams1980 = teamsStatsDF[teamsStatsDF[\"yearID\"] >=1980]\n",
    "teams1980.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to do the data manipulation steps in TeamBattingML\n",
    "# dfTeamStats - the teamStatsDF as read from DB\n",
    "# latesDataYear - the furthest year back you want data from \n",
    "# stat - the stat you are trying to predict (winPct)\n",
    "# reachYears - how many years of historical data you want to use\n",
    " \n",
    "\n",
    "def manipulateTeamDF(dfTeamStats, latestDataYear, stat, reachYears):\n",
    "    \n",
    "    # Get data going back to latest year of interest\n",
    "    targetTeamsDF = teamsStatsDF[teamsStatsDF[\"yearID\"] >=latestDataYear]\n",
    "    \n",
    "    # Limit to columns of interest\n",
    "    colsOfInterst = [\"franchiseID\", \"yearID\",\"teamID\", \"G\", \"W\", \"R\", \"H\", \"HR\", \"BB\"]\n",
    "    targetTeamsDF = targetTeamsDF[colsOfInterst]\n",
    "    \n",
    "    # add a teams only column\n",
    "    targetTeamsDF[\"teamOnly\"] = \"\"\n",
    "    for index, row in targetTeamsDF.iterrows():\n",
    "        teamID = row[\"teamID\"]\n",
    "        teamOnly = teamID.split(\"-\")[0]\n",
    "        targetTeamsDF.at[index, \"teamOnly\"] = teamOnly\n",
    "    \n",
    "    # Find first year, last year, and total years of franchise\n",
    "    teamYearsDF = targetTeamsDF[[\"teamOnly\", \"yearID\"]]\n",
    "    teamYearsDF = teamYearsDF.groupby(\"teamOnly\").agg(['min', 'max', 'count'])\n",
    "    teamYearsDF = teamYearsDF.reset_index()\n",
    "    teamYearsDF.columns = teamYearsDF.columns.droplevel()\n",
    "    teamYearsDF = teamYearsDF.rename(columns={\"\": \"teamOnly\",\n",
    "                                              \"min\": \"firstYear\",\n",
    "                                             \"max\": \"lastYear\",\n",
    "                                             \"count\": \"totalYears\"})\n",
    "    # Merge Years Data with target data\n",
    "    targetTeamsDF = pd.merge(targetTeamsDF, teamYearsDF, on = [\"teamOnly\"])\n",
    "\n",
    "    # Create field for yearofTeam\n",
    "    targetTeamsDF[\"teamYr\"] = targetTeamsDF[\"yearID\"] + 1 - targetTeamsDF[\"firstYear\"]\n",
    "    \n",
    "    # Add a winPCT field and make stats per game stats\n",
    "    targetTeamsDF[\"winPct\"] = targetTeamsDF.W / targetTeamsDF.G\n",
    "    targetTeamsDF[\"RpG\"] = targetTeamsDF.R / targetTeamsDF.G\n",
    "    targetTeamsDF[\"HpG\"] = targetTeamsDF.H / targetTeamsDF.G\n",
    "    targetTeamsDF[\"HRpG\"] = targetTeamsDF.HR / targetTeamsDF.G\n",
    "    targetTeamsDF[\"BBpG\"] = targetTeamsDF.BB / targetTeamsDF.G\n",
    "\n",
    "    # Then keep only perGame cols\n",
    "    perGameCols = ['franchiseID', 'yearID', 'teamID', 'G', 'winPct', \n",
    "                   'RpG', 'HpG', 'HRpG', 'BBpG', 'firstYear', 'lastYear', 'totalYears', 'teamYr']\n",
    "    targetTeamsDF = targetTeamsDF[perGameCols]\n",
    "    \n",
    "    \n",
    "    # Add a column to indicate rows that should be skipped\n",
    "    #  years < latestDataYear + 2 (we can't get 2 year previous data for these years)\n",
    "    #  teamYr < 3 (we can't get 2 year previous data for these years)\n",
    "    #  year = lastYear (we can't use next year to check model)\n",
    "    #  year = 2019 (last year of our data so )\n",
    "\n",
    "    targetTeamsDF[\"skip\"] = 0\n",
    "    for index, row in targetTeamsDF.iterrows():\n",
    "        if row[\"yearID\"] < (latestDataYear + reachYears):\n",
    "            targetTeamsDF.at[index, \"skip\"] = 1\n",
    "        elif row[\"teamYr\"] < 3:\n",
    "            targetTeamsDF.at[index, \"skip\"] = 1\n",
    "        elif row[\"yearID\"] == row[\"lastYear\"]:\n",
    "            targetTeamsDF.at[index, \"skip\"] = 1\n",
    "        elif row[\"yearID\"] == 2019:\n",
    "            targetTeamsDF.at[index, \"skip\"] = 2\n",
    "            \n",
    "    # SOrt by teamID (team and year) - to get all franchise data together\n",
    "    sortedTeamsDF = targetTeamsDF.sort_values(by = [\"teamID\"])\n",
    "    sortedTeamsDF = sortedTeamsDF.reset_index(drop=True)\n",
    "    \n",
    "    # Iterate through the sorted batting and grab previous stats\n",
    "    mlDF = sortedTeamsDF.copy()\n",
    "    # playersMLBatting = playersMLBatting.drop(columns=[\"birthYear\", \"debuYear\"])\n",
    "\n",
    "    # Make Columns labels based on stat\n",
    "    p2Label = \"p2-\" + stat\n",
    "    p1Label = \"p1-\" + stat\n",
    "    f1Label = \"f1-\" + stat\n",
    "    # Add those columns to DF\n",
    "    mlDF[p2Label] = \"\"\n",
    "    mlDF[p1Label] = \"\"\n",
    "    mlDF[f1Label] = \"\"\n",
    "\n",
    "    # Itterate through DF and populate those columns\n",
    "    for index, row in mlDF.iterrows():\n",
    "        if row[\"skip\"] == 1:\n",
    "            continue\n",
    "        elif row[\"skip\"] == 2:\n",
    "            p2Stat = mlDF.iloc[index - 2][stat]\n",
    "            p1Stat = mlDF.iloc[index - 1][stat]\n",
    "            \n",
    "            mlDF.at[index, p2Label] = p2Stat\n",
    "            mlDF.at[index, p1Label] = p1Stat\n",
    "        else:    \n",
    "            p2Stat = mlDF.iloc[index - 2][stat]\n",
    "            p1Stat = mlDF.iloc[index - 1][stat]\n",
    "            f1Stat = mlDF.iloc[index + 1][stat]\n",
    "\n",
    "            mlDF.at[index, p2Label] = p2Stat\n",
    "            mlDF.at[index, p1Label] = p1Stat\n",
    "            mlDF.at[index, f1Label] = f1Stat\n",
    "            \n",
    "            \n",
    "    # # Get rid of the skipped rows, then all complete data\n",
    "    mlData = mlDF.loc[mlDF['skip'] == 0]\n",
    "    \n",
    "    return mlData\n",
    "    return mlDF\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePredsTabel(df, inputs_list):\n",
    "    newDF = df.copy()\n",
    "    # Create a column to hold prediction values\n",
    "    newDF[\"model\"] = \"\"\n",
    "    \n",
    "    #Creat columns lists - for Dicts that will then be converted to DFs\n",
    "    linearYears = []\n",
    "    linearTeams = []\n",
    "    linearActual = []\n",
    "    linearModel = []\n",
    "    linearType = []\n",
    "    \n",
    "    ridgeYears = []\n",
    "    ridgeTeams = []\n",
    "    ridgeActual = []\n",
    "    ridgeModel = []\n",
    "    ridgeType = []\n",
    "    \n",
    "    lassoYears = []\n",
    "    lassoTeams = []\n",
    "    lassoActual = []\n",
    "    lassoModel = []\n",
    "    lassoType = []\n",
    "    \n",
    "    eNetYears = []\n",
    "    eNetTeams = []\n",
    "    eNetActual = []\n",
    "    eNetModel = []\n",
    "    eNetType = []\n",
    "    \n",
    "    # Loop through df and make predictions and update columns lists\n",
    "    inputFactors = [\"p2-winPct\", \"p1-winPct\", \"winPct\"]\n",
    "    inputFactors.extend(inputs_list)\n",
    "    for index, row in newDF.iterrows():\n",
    "        yr = row[\"yearID\"]\n",
    "        team = row[\"franchiseID\"]\n",
    "        actual = row[\"winPct\"]\n",
    "        \n",
    "        rowSelected = newDF.loc[[index]]\n",
    "\n",
    "        lin_pred = teamBatting2Model[0].predict(rowSelected[inputFactors])[0][0]\n",
    "        linearYears.append(yr)\n",
    "        linearTeams.append(team + \"-\" + str(yr))\n",
    "        linearActual.append(actual)\n",
    "        linearModel.append(lin_pred)\n",
    "        linearType.append(\"ML-LN-T1\")\n",
    "        \n",
    "        ridge_pred = teamBatting2Model[1].predict(rowSelected[inputFactors])[0][0]\n",
    "        ridgeYears.append(yr)\n",
    "        ridgeTeams.append(team + \"-\" + str(yr))\n",
    "        ridgeActual.append(actual)\n",
    "        ridgeModel.append(ridge_pred)\n",
    "        ridgeType.append(\"ML-RD-T1\")\n",
    "        \n",
    "        lasso_pred = teamBatting2Model[2].predict(rowSelected[inputFactors])[0]\n",
    "        lassoYears.append(yr)\n",
    "        lassoTeams.append(team + \"-\" + str(yr))\n",
    "        lassoActual.append(actual)\n",
    "        lassoModel.append(lasso_pred)\n",
    "        lassoType.append(\"ML-LS-T1\")\n",
    "        lasso_type = \"ML-LS-T1\"\n",
    "        \n",
    "        eNet_pred = teamBatting2Model[3].predict(rowSelected[inputFactors])[0]    \n",
    "        eNetYears.append(yr)\n",
    "        eNetTeams.append(team + \"-\" + str(yr))\n",
    "        eNetActual.append(actual)\n",
    "        eNetModel.append(eNet_pred)\n",
    "        eNetType.append(\"ML-EN-T1\")\n",
    "        \n",
    "    # Make dictionaries with the columns created\n",
    "    linDict = {\"yearID\": linearYears,\n",
    "              \"teamID\": linearTeams,\n",
    "              \"actual\": linearActual,\n",
    "              \"model\": linearModel,\n",
    "              \"model_type\": linearType}\n",
    "    linDF = pd.DataFrame.from_dict(linDict)\n",
    "    \n",
    "    ridgeDict = {\"yearID\": ridgeYears,\n",
    "              \"teamID\": ridgeTeams,\n",
    "              \"actual\": ridgeActual,\n",
    "              \"model\": ridgeModel,\n",
    "              \"model_type\": ridgeType}\n",
    "    ridgeDF = pd.DataFrame.from_dict(ridgeDict)\n",
    "    \n",
    "    lassoDict = {\"yearID\": lassoYears,\n",
    "              \"teamID\": lassoTeams,\n",
    "              \"actual\": lassoActual,\n",
    "              \"model\": lassoModel,\n",
    "              \"model_type\": lassoType}\n",
    "    lassoDF = pd.DataFrame.from_dict(lassoDict)\n",
    "    \n",
    "    eNetDict = {\"yearID\": eNetYears,\n",
    "              \"teamID\": eNetTeams,\n",
    "              \"actual\": eNetActual,\n",
    "              \"model\": eNetModel,\n",
    "              \"model_type\": eNetType}\n",
    "    eNetDF = pd.DataFrame.from_dict(eNetDict)\n",
    "    \n",
    "    fullDF = linDF.append(ridgeDF)\n",
    "    fullDF = fullDF.append(lassoDF)\n",
    "    fullDF = fullDF.append(eNetDF)\n",
    "    \n",
    "    return fullDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Split data and run model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "def run_ML_Model(mlDF, stat, inputs_list):\n",
    "    mlData = mlDF.loc[mlDF['skip'] == 0]\n",
    "    p2Label = \"p2-\" + stat\n",
    "    p1Label = \"p1-\" + stat\n",
    "    f1Label = \"f1-\" + stat\n",
    "    \n",
    "    print(\"== All Inputs ==\")\n",
    "    inputFactors = [p2Label, p1Label, stat]\n",
    "    inputFactors.extend(inputs_list)\n",
    "    print(f\"Input Factors: {inputFactors}\")\n",
    "    X = mlData[inputFactors]\n",
    "    y = mlData[[f1Label]]\n",
    "    \n",
    "    # Split Data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=5)\n",
    "    \n",
    "    #==============================LinearModel===============\n",
    "    model_lin = LinearRegression()\n",
    "    model_lin.fit(X_train, y_train)\n",
    "    # Calculate the R2 scores\n",
    "    training_score_lin = model_lin.score(X_train, y_train)\n",
    "    testing_score_lin = model_lin.score(X_test, y_test)\n",
    "    # Make Predictions and get MSE\n",
    "    preds_lin = model_lin.predict(X_test)\n",
    "    MSE_lin = mean_squared_error(y_test, preds_lin)\n",
    "    # Get coeffs and Y-int\n",
    "    coeffs_lin = model_lin.coef_.tolist()[0]\n",
    "    y_int_lin = model_lin.intercept_.tolist()[0]\n",
    "    print(\"===================\")\n",
    "    print(\"=== Linear ===\")\n",
    "    print(f\"{stat}: Training Score: {training_score_lin}\")\n",
    "    print(f\"{stat}:Testing Score: {testing_score_lin}\")\n",
    "    print(f\"{stat}:MSE: {MSE_lin}\")\n",
    "    print('Weight coefficients: ', coeffs_lin)\n",
    "    print('y-axis intercept: ', y_int_lin)\n",
    "    print(\"===================\")\n",
    "    \n",
    "    \n",
    "    #===============================RidgeModel===============\n",
    "    model_ridge = Ridge(alpha=0.01).fit(X_train, y_train)\n",
    "    # Calculate the R2 scores\n",
    "    training_score_ridge= model_ridge.score(X_train, y_train)\n",
    "    testing_score_ridge = model_ridge.score(X_test, y_test)\n",
    "    # Make Predictions and get MSE\n",
    "    preds_ridge = model_ridge.predict(X_test)\n",
    "    MSE_ridge = mean_squared_error(y_test, preds_ridge)\n",
    "    # Get coeffs and Y-int\n",
    "    coeffs_ridge= model_ridge.coef_.tolist()[0]\n",
    "    y_int_ridge = model_ridge.intercept_.tolist()[0]\n",
    "    print(\"===================\")\n",
    "    print(\"=== Ridge ===\")\n",
    "    print(f\"{stat}: Training Score: {training_score_ridge}\")\n",
    "    print(f\"{stat}:Testing Score: {testing_score_ridge}\")\n",
    "    print(f\"{stat}:MSE: {MSE_ridge}\")\n",
    "    print('Weight coefficients: ', coeffs_ridge)\n",
    "    print('y-axis intercept: ', y_int_ridge)\n",
    "    print(\"===================\")\n",
    "    \n",
    "    #=================================LassoModel===============\n",
    "    model_lasso = Lasso(alpha=0.01).fit(X_train, y_train)\n",
    "    # Calculate the R2 scores\n",
    "    training_score_lasso= model_lasso.score(X_train, y_train)\n",
    "    testing_score_lasso = model_lasso.score(X_test, y_test)\n",
    "    # Make Predictions and get MSE\n",
    "    preds_lasso = model_lasso.predict(X_test)\n",
    "    MSE_lasso = mean_squared_error(y_test, preds_lasso)\n",
    "    # Get coeffs and Y-int\n",
    "    coeffs_lasso= model_lasso.coef_.tolist()[0]\n",
    "    y_int_lasso = model_lasso.intercept_.tolist()[0]\n",
    "    print(\"===================\")\n",
    "    print(\"=== Lasso ===\")\n",
    "    print(f\"{stat}: Training Score: {training_score_lasso}\")\n",
    "    print(f\"{stat}:Testing Score: {testing_score_lasso}\")\n",
    "    print(f\"{stat}:MSE: {MSE_lasso}\")\n",
    "    print('Weight coefficients: ', coeffs_lasso)\n",
    "    print('y-axis intercept: ', y_int_lasso)\n",
    "    print(\"===================\")\n",
    "    \n",
    "    #================================ElasticNetModel===============\n",
    "    model_eNet = ElasticNet(alpha=.01, l1_ratio=0.001).fit(X_train, y_train)\n",
    "    # Calculate the R2 scores\n",
    "    training_score_eNet= model_eNet.score(X_train, y_train)\n",
    "    testing_score_eNet = model_eNet.score(X_test, y_test)\n",
    "    # Make Predictions and get MSE\n",
    "    preds_eNet = model_eNet.predict(X_test)\n",
    "    MSE_eNet = mean_squared_error(y_test, preds_eNet)\n",
    "    # Get coeffs and Y-int\n",
    "    coeffs_eNet= model_eNet.coef_.tolist()[0]\n",
    "    y_int_eNet = model_eNet.intercept_.tolist()[0]\n",
    "    print(\"===================\")\n",
    "    print(\"=== Elastic Net ===\")\n",
    "    print(f\"{stat}: Training Score: {training_score_eNet}\")\n",
    "    print(f\"{stat}:Testing Score: {testing_score_eNet}\")\n",
    "    print(f\"{stat}:MSE: {MSE_eNet}\")\n",
    "    print('Weight coefficients: ', coeffs_eNet)\n",
    "    print('y-axis intercept: ', y_int_eNet)\n",
    "    print(\"===================\")\n",
    "    \n",
    "    \n",
    "    return (model_lin, model_ridge, model_lasso, model_eNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1033, 17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comment after Executing\n",
    "\n",
    "teamBatting2 = manipulateTeamDF(teamsStatsDF, 1980, \"winPct\", 2)\n",
    "teamBatting2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teamBatting2Model = run_ML_Model(teamBatting2, \"winPct\", [\"RpG\", \"HpG\", \"HRpG\", \"BBpG\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearID</th>\n",
       "      <th>teamID</th>\n",
       "      <th>actual</th>\n",
       "      <th>model</th>\n",
       "      <th>model_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>2017</td>\n",
       "      <td>WSN-2017</td>\n",
       "      <td>0.598765</td>\n",
       "      <td>0.554544</td>\n",
       "      <td>ML-RD-T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>2018</td>\n",
       "      <td>WSN-2018</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.525335</td>\n",
       "      <td>ML-EN-T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>2018</td>\n",
       "      <td>WSN-2018</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.519844</td>\n",
       "      <td>ML-LN-T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>2018</td>\n",
       "      <td>WSN-2018</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.500599</td>\n",
       "      <td>ML-LS-T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>2018</td>\n",
       "      <td>WSN-2018</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.519915</td>\n",
       "      <td>ML-RD-T1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      yearID    teamID    actual     model model_type\n",
       "1031    2017  WSN-2017  0.598765  0.554544   ML-RD-T1\n",
       "1032    2018  WSN-2018  0.506173  0.525335   ML-EN-T1\n",
       "1032    2018  WSN-2018  0.506173  0.519844   ML-LN-T1\n",
       "1032    2018  WSN-2018  0.506173  0.500599   ML-LS-T1\n",
       "1032    2018  WSN-2018  0.506173  0.519915   ML-RD-T1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullDFTry = makePredsTabel(teamBatting2, [\"RpG\", \"HpG\", \"HRpG\", \"BBpG\"])\n",
    "fullDFTry = fullDFTry.sort_values(by=['teamID', \"model_type\"])\n",
    "fullDFTry.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\..\\\\data\\\\csv\\\\models\\\\teamPredictions.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-db540a7e4f2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msavePath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"..\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"models\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"teamPredictions.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfullDFTry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msavePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3203\u001b[0m         )\n\u001b[1;32m-> 3204\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m             )\n\u001b[0;32m    190\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\..\\\\data\\\\csv\\\\models\\\\teamPredictions.csv'"
     ]
    }
   ],
   "source": [
    "savePath = os.path.join(\"..\", \"..\", \"data\", \"csv\", \"models\", \"teamPredictions.csv\")\n",
    "fullDFTry.to_csv(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
